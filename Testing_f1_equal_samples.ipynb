{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing_f1_equal_samples.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/selimelawwa/Speaker_Verification/blob/master/Testing_f1_equal_samples.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "XOpBYNdZZKtA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IfyEhaDGZNaR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qA3etWm9ZNuE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmGjt2i2gR1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!pip install librosa\n",
        "!pip install imbalanced-learn\n",
        "!pip install pydub\n",
        "!pip install python_speech_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVCYqH9ogZVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from keras.models import load_model,Model\n",
        "import numpy as np\n",
        "#data specs\n",
        "feature_dim_1 = 80  #time\n",
        "feature_dim_2 = 40  #frequency\n",
        "channel = 1\n",
        "\n",
        "#numpy\n",
        "numpy_files_path = \"drive/big-numpy-data/\"\n",
        "numpy_test_path = \"drive/big-numpy-test/\"\n",
        "\n",
        "def get_labels(path):\n",
        "    #get folder name 'label' for each speaker\n",
        "    labels = os.listdir(path)\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUgOk0kPZNxl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model(model,test_numpy_files_path,threshold):\n",
        "    labels = get_labels(test_numpy_files_path)\n",
        "    threshold_distance = threshold\n",
        "    overall_accuracy_with_fake_data=0 #Accuracy when testing with user data\n",
        "    overall_accuracy_with_true_data=0   #Accuracy when testing with fake data \n",
        "    overall_precision = 0\n",
        "    overall_recall = 0\n",
        "    overall_f1 = 0 \n",
        "    for label in labels:\n",
        "        #Load user numpy files\n",
        "        user_files = np.load(test_numpy_files_path + label)\n",
        "        #Creat user embeddings(enrollment)\n",
        "        user_embs = model.predict(user_files[0].reshape(1,user_files[0].shape[0], user_files[0].shape[1], 1))\n",
        "        for i in range(1,5):\n",
        "            user_embs = user_embs + model.predict(user_files[i].reshape(1,user_files[i].shape[0], user_files[i].shape[1], 1))\n",
        "        user_embs = user_embs / 5\n",
        "        #Test against the user numpy files (Should get cosine distance near 1.0 and allow)\n",
        "        honest_test_cases_count = 0     #number of test cases with user data\n",
        "        fake_test_cases_count = 0\n",
        "        true_negative=0 \n",
        "        accuracy_with_fake_data=0\n",
        "        true_positive = 0\n",
        "        false_negative = 0\n",
        "        false_positive = 0\n",
        "        accuracy_with_user_data = 0\n",
        "        precision_of_user = 0\n",
        "        recall_of_user = 0\n",
        "        for i in range(5,user_files.shape[0]):\n",
        "            honest_test_cases_count+=1     #increment number of test cases with user data\n",
        "            calculated_embs = model.predict(user_files[i].reshape(1,user_files[i].shape[0], user_files[i].shape[1], 1))\n",
        "            #get cosine distance between user saved embeddings and test case embeddings\n",
        "            distance = cosine_similarity(user_embs,calculated_embs)\n",
        "            #if distance >= threshold_distance will accept this test case\n",
        "            if distance >= threshold_distance:\n",
        "                #correctly_allowed +=1\n",
        "                true_positive +=1\n",
        "            else:\n",
        "              false_negative +=1\n",
        "            #else it will be in correctly dis-allowed\n",
        "        accuracy_with_user_data = true_positive / honest_test_cases_count\n",
        "        \n",
        "        #Now will test user against all other users ( should get cosine distance close to 0 and dont allow)\n",
        "        fake_users_list = labels.copy()#this list will contain all users in dataset excep current enrolled user\n",
        "        fake_users_list.remove(label)#remove enrolled user from list of fake users\n",
        "        \n",
        "        test_fake_users_index = np.arange(len(fake_users_list))\n",
        "        np.random.shuffle(test_fake_users_index)\n",
        "        \n",
        "        for i in range(honest_test_cases_count):\n",
        "            if i < len(test_fake_users_index):\n",
        "                target_index = test_fake_users_index[i]\n",
        "            else:\n",
        "                target_index = test_fake_users_index[i%len(test_fake_users_index)]\n",
        "            fake_user_files = np.load(test_numpy_files_path + fake_users_list[target_index])\n",
        "            target_file_index = np.random.randint(low=0,high=fake_user_files.shape[0])\n",
        "            calculated_embs = model.predict(fake_user_files[target_file_index].reshape(1,fake_user_files[target_file_index].shape[0], fake_user_files[target_file_index].shape[1], 1))\n",
        "            distance = cosine_similarity(user_embs,calculated_embs)\n",
        "            fake_test_cases_count+=1\n",
        "            #if distance < threshold then we will not accept this case\n",
        "            if distance < threshold_distance:\n",
        "                true_negative +=1\n",
        "            else:\n",
        "              false_positive +=1\n",
        "        accuracy_with_fake_data = true_negative / fake_test_cases_count\n",
        "        \n",
        "        precision_of_user = true_positive / (true_positive + false_positive)\n",
        "        recall_of_user = true_positive / (true_positive + false_negative)\n",
        "        f1_user = 2 * (precision_of_user * recall_of_user ) / (precision_of_user + recall_of_user )\n",
        "        \n",
        "        overall_precision += precision_of_user\n",
        "        overall_recall += recall_of_user\n",
        "        overall_f1 += f1_user\n",
        "        overall_accuracy_with_fake_data += accuracy_with_fake_data\n",
        "        overall_accuracy_with_true_data += accuracy_with_user_data\n",
        "    overall_precision = overall_precision / len(labels)\n",
        "    overall_recall = overall_recall / len(labels)\n",
        "    overall_f1 = overall_f1 / len(labels)\n",
        "    overall_accuracy_with_true_data = overall_accuracy_with_true_data / len(labels)\n",
        "    overall_accuracy_with_fake_data = overall_accuracy_with_fake_data / len(labels)\n",
        "\n",
        "    return overall_precision,overall_recall,overall_f1,overall_accuracy_with_true_data,overall_accuracy_with_fake_data\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBbDO9saiOyw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loading pre-trained model\n",
        "loaded_model = load_model('drive/model_21June.h5')\n",
        "#Removing last layer and creating updated model\n",
        "inp = loaded_model.input\n",
        "out = loaded_model.layers[-3].output\n",
        "#Crearing new model which is old model with final layer removed\n",
        "model = Model(inp, out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vK9lhij2hZCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b0bec552-f148-451d-9407-e681bd888a7a"
      },
      "cell_type": "code",
      "source": [
        "overall_precision,overall_recall,overall_f1,overall_accuracy_with_true_data,overall_accuracy_with_fake_data = test_model(model=model,test_numpy_files_path=numpy_test_path,threshold=0.7)\n",
        "print(\"Testing with threshold: 0.7\")\n",
        "print(\"overall_accuracy_with_true_data\",overall_accuracy_with_true_data,\"overall_accuracy_with_fake_data\",overall_accuracy_with_fake_data)\n",
        "print(\"overall_precision; \",overall_precision,\" overall_recall: \",overall_recall)\n",
        "print(\"overall_f1:\",overall_f1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing with threshold: 0.7\n",
            "overall_accuracy_with_true_data 0.7054980252252031 overall_accuracy_with_fake_data 0.9808118430143105\n",
            "overall_precision;  0.9715896167670776  overall_recall:  0.7054980252252031\n",
            "overall_f1: 0.7922697463077286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gx-ABjF7poHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2b71e9c3-e07c-49de-fa41-bff083081749"
      },
      "cell_type": "code",
      "source": [
        "overall_precision,overall_recall,overall_f1,overall_accuracy_with_true_data,overall_accuracy_with_fake_data = test_model(model=model,test_numpy_files_path=numpy_test_path,threshold=0.65)\n",
        "print(\"Testing with threshold: 0.65\")\n",
        "print(\"overall_accuracy_with_true_data\",overall_accuracy_with_true_data,\"overall_accuracy_with_fake_data\",overall_accuracy_with_fake_data)\n",
        "print(\"overall_precision; \",overall_precision,\" overall_recall: \",overall_recall)\n",
        "print(\"overall_f1:\",overall_f1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing with threshold: 0.65\n",
            "overall_accuracy_with_true_data 0.7992825653326177 overall_accuracy_with_fake_data 0.9596852796698138\n",
            "overall_precision;  0.9515833054305678  overall_recall:  0.7992825653326177\n",
            "overall_f1: 0.8542308780849049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gjNAq6iDtU67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "13ddfd8a-c751-4f72-fc60-de9799e3d46d"
      },
      "cell_type": "code",
      "source": [
        "overall_precision,overall_recall,overall_f1,overall_accuracy_with_true_data,overall_accuracy_with_fake_data = test_model(model=model,test_numpy_files_path=numpy_test_path,threshold=0.6)\n",
        "print(\"Testing with threshold: 0.6\")\n",
        "print(\"overall_accuracy_with_true_data\",overall_accuracy_with_true_data,\"overall_accuracy_with_fake_data\",overall_accuracy_with_fake_data)\n",
        "print(\"overall_precision; \",overall_precision,\" overall_recall: \",overall_recall)\n",
        "print(\"overall_f1:\",overall_f1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing with threshold: 0.6\n",
            "overall_accuracy_with_true_data 0.8667682438024137 overall_accuracy_with_fake_data 0.931732157530077\n",
            "overall_precision;  0.9266325268978536  overall_recall:  0.8667682438024137\n",
            "overall_f1: 0.8885180944478699\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}